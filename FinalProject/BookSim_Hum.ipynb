{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyyoo/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import scipy.sparse as sparse\n",
    "import sklearn.metrics as metrics\n",
    "import sys as sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata = pd.read_csv(\"Test_Train_Sets/Hum_test.csv\")\n",
    "traindata = pd.read_csv(\"Test_Train_Sets/Hum_train.csv\")\n",
    "valdata = pd.read_csv(\"Test_Train_Sets/Hum_validate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15053, 18), (1116, 18), (1488, 18))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.shape, testdata.shape, valdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3043 different books and 7113 different users in traindata\n",
      "643 different books and 372 different users in testdata\n",
      "803 different books and 372 different users in valdata\n"
     ]
    }
   ],
   "source": [
    "print '%d different books and %d different users in traindata' %(np.unique(traindata['Title']).shape[0],np.unique(traindata['ID']).shape[0])\n",
    "print '%d different books and %d different users in testdata' %(np.unique(testdata['Title']).shape[0],np.unique(testdata['ID']).shape[0])\n",
    "print '%d different books and %d different users in valdata' %(np.unique(valdata['Title']).shape[0],np.unique(valdata['ID']).shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataframe that contains only useful informations\n",
    "usefulcol = ['Title','ID','Class','Category','Author','ISBN','Count','Address1','Address2','Publisher']\n",
    "dftrain = traindata[usefulcol]\n",
    "dftest = testdata[usefulcol]\n",
    "dfval = valdata[usefulcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3043 2608 709\n"
     ]
    }
   ],
   "source": [
    "title_train = np.unique(dftrain['Title'].values)\n",
    "author_train = np.unique(dftrain['Author'].values)\n",
    "publisher_train = np.unique(dftrain['Publisher'].values)\n",
    "title_train_dict = {i:t for i,t in enumerate(title_train)}\n",
    "author_train_dict = {i:t for i,t in enumerate(author_train)}\n",
    "publisher_train_dict = {i:t for i,t in enumerate(publisher_train)}\n",
    "print title_train.shape[0],author_train.shape[0],publisher_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def author_to_list(author):\n",
    "    #split the list of authors in a single string into a numpy list of authors. remove brackets, '저', '역', '그림', '/', and etc\n",
    "    #remove translater\n",
    "    if author != author:\n",
    "        newauthorlist = []\n",
    "    else:\n",
    "        split_list = np.array(['/'])\n",
    "        mask = np.array([s in author for s in split_list])\n",
    "        split_list = split_list[mask]\n",
    "        \n",
    "        for s in split_list:\n",
    "            author = re.sub(s,' ..',author)\n",
    "        authorlist = author.split(' ..')\n",
    "        authorlist = np.array(filter(None,authorlist))\n",
    "        \n",
    "        translatormask = np.array([(' 역' in a) or (' 공역' in a) or \n",
    "                                   (' 편역' in a) or (' 감수' in a) or \n",
    "                                   (' 옮김' in a) or (' 등역' in a) or\n",
    "                                   (' 엮음' in a) for a in authorlist])\n",
    "        authorlist = authorlist[~translatormask]\n",
    "        \n",
    "        remove_str_list = np.array(['<','>',' 그림',' 저',' 공저',' 글', ' 등저',' 공편','편'])\n",
    "        newauthorlist = np.array([])\n",
    "        for astr in authorlist:\n",
    "            alist = np.array(astr.split(','))\n",
    "            for i,a in enumerate(alist):\n",
    "                for s in remove_str_list:\n",
    "                    a = re.sub(s,'',a)\n",
    "                alist.flat[i]=a\n",
    "            newauthorlist = np.append(newauthorlist,alist)\n",
    "                \n",
    "    return newauthorlist       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataframe of all books (no duplicates)\n",
    "dfbook = dftrain[['Author','Title','Publisher','ISBN']]\n",
    "dfbook = dfbook[~dfbook.duplicated()]\n",
    "dfbook = dfbook.reset_index()\n",
    "dfbook.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2605,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_entire_list = np.array([])\n",
    "for a in author_train:\n",
    "    author_entire_list = np.append(author_entire_list,author_to_list(a))\n",
    "author_entire_list = np.unique(author_entire_list)\n",
    "author_entire_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_entire_list_dict = {i:a for i,a in enumerate(author_entire_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make binary author lists: Nbooks X Nauthors matrix\n",
    "#Use author_entire_list for index-author matching\n",
    "Xauthor = np.zeros((dfbook.index.shape[0],author_entire_list.shape[0]))\n",
    "for ind in dfbook.index:\n",
    "    alist = author_to_list(dfbook.iloc[ind]['Author'])\n",
    "    for a in alist:\n",
    "        aind = np.where(author_entire_list==a)[0][0]\n",
    "        Xauthor[ind,aind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('Xauthor_Hum.txt',Xauthor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make binary publisher lists: Nbooks X Npublihser matrix\n",
    "#use publisher_train or publisher_train_dict for index matching\n",
    "Xpublisher = np.zeros((dfbook.index.shape[0],publisher_train.shape[0]))\n",
    "for ind in dfbook.index:\n",
    "    pub = dfbook.iloc[ind]['Publisher']\n",
    "    pind = np.where(publisher_train==pub)[0][0]\n",
    "    Xpublisher[ind,pind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('Xpublisher_Hum.txt',Xpublisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36min 53s, sys: 40.3 s, total: 37min 33s\n",
      "Wall time: 37min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Make similarity matrix for titles: Nbooks X Nbooks matrix\n",
    "#Use dfbooks for index-title matching\n",
    "Nbooks =dfbook.index.shape[0]\n",
    "simmat_title = np.zeros((Nbooks,Nbooks))\n",
    "for i in range(Nbooks):\n",
    "    simmat_title[i,i] = 1.0\n",
    "    for j in range(i+1,Nbooks):\n",
    "        simmat_title[i,j] = similar(dfbook.iloc[i]['Title'],dfbook.iloc[j]['Title'])\n",
    "        simmat_title[j,i] = simmat_title[i,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('simmat_title_Hum.txt',simmat_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simmat_author = Xauthor.dot(Xauthor.T)\n",
    "simmat_publisher = Xpublisher.dot(Xpublisher.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simmat = 0.5*simmat_title+0.4*simmat_author+0.1*simmat_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_based_on_similarity(dftrain,userid,Nrec,simmat,dfbook=dfbook):\n",
    "    #recommend Nrec books similar to the books that the chosen user has bought so far\n",
    "    #input: \n",
    "    # dftrain: training data\n",
    "    # userid: id of the user\n",
    "    # Nrec: Number of books to be recommended\n",
    "    # dfbook: the dataframes of books\n",
    "    # simmat: Nbooks X Nbooks similarity matrix\n",
    "    usertrans = dftrain[dftrain['ID']==userid]  #user transaction\n",
    "    usertrans = usertrans[['Author','Title','Publisher','ISBN']]\n",
    "    usertrans = usertrans[~usertrans.duplicated()]\n",
    "    excludeind = np.array([])\n",
    "    simvec = np.zeros(simmat.shape[1])\n",
    "    for ind in usertrans.index:\n",
    "        bookind = dfbook[(dfbook['Title']==usertrans[usertrans.index == ind]['Title'].values[0]) \n",
    "                         & (dfbook['Publisher']==usertrans[usertrans.index == ind]['Publisher'].values[0])].index[0]\n",
    "        simvec = simvec+simmat[bookind,:]\n",
    "        excludeind = np.append(excludeind,[bookind])\n",
    "    simvec = simvec/usertrans.index.shape[0]\n",
    "    dfsimvec = dfbook\n",
    "    dfsimvec['Similarity'] = simvec\n",
    "\n",
    "    dfsimvec = dfsimvec.iloc[filter(lambda x: x not in excludeind,dfsimvec.index)]\n",
    "    return dfsimvec.sort('Similarity',ascending=False)[:Nrec]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>&lt;오세정&gt;,&lt;손동현&gt;,&lt;문광훈&gt;,&lt;최장집&gt;,&lt;이승환&gt;,&lt;김민환&gt; 공저</td>\n",
       "      <td>문화의 안과 밖 2 인간적 사회의 기초</td>\n",
       "      <td>민음사</td>\n",
       "      <td>9.788937e+12</td>\n",
       "      <td>0.372564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>&lt;강신주&gt;,&lt;서동욱&gt;,&lt;우석훈&gt;,&lt;장대익&gt;,&lt;하지현&gt; 공저</td>\n",
       "      <td>한 평생의 지식</td>\n",
       "      <td>민음사</td>\n",
       "      <td>9.788937e+12</td>\n",
       "      <td>0.261957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>소걀 린포체 저/오진탁 역</td>\n",
       "      <td>티베트의 지혜</td>\n",
       "      <td>민음사</td>\n",
       "      <td>9.788937e+12</td>\n",
       "      <td>0.261111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>&lt;김방한&gt; 저</td>\n",
       "      <td>언어학의 이해</td>\n",
       "      <td>민음사</td>\n",
       "      <td>9.788937e+12</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Author                  Title Publisher          ISBN  Similarity\n",
       "3075  <오세정>,<손동현>,<문광훈>,<최장집>,<이승환>,<김민환> 공저  문화의 안과 밖 2 인간적 사회의 기초       민음사  9.788937e+12    0.372564\n",
       "1269        <강신주>,<서동욱>,<우석훈>,<장대익>,<하지현> 공저               한 평생의 지식       민음사  9.788937e+12    0.261957\n",
       "958                           소걀 린포체 저/오진탁 역                티베트의 지혜       민음사  9.788937e+12    0.261111\n",
       "1283                                 <김방한> 저                언어학의 이해       민음사  9.788937e+12    0.250000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_based_on_similarity(dftrain,dftest['ID'].values[10],4,simmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_percentage(dftrain,dftest,Nrec,weightdict,simmat_author=simmat_author,\n",
    "                       simmat_title=simmat_title,simmat_publisher=simmat_publisher,dfbook=dfbook):\n",
    "    simmat = weightdict['Author']*simmat_author+weightdict['Title']*simmat_title\n",
    "    +weightdict['Publisher']*simmat_publisher\n",
    "    testusers = np.unique(dftest['ID'].values)\n",
    "    totalbooks = 0\n",
    "    totalsuccess = 0\n",
    "    for user in testusers:\n",
    "        dfrec = recommend_based_on_similarity(dftrain,user,Nrec,simmat,dfbook=dfbook)\n",
    "        dftestuser = dftest[dftest['ID']==user]\n",
    "        totalbooks = totalbooks+Nrec\n",
    "        for i in range(dfrec.shape[0]):\n",
    "            if np.any((dftestuser['Title']==dfrec.iloc[i]['Title']) \n",
    "                & (dftestuser['Publisher']==dfrec.iloc[i]['Publisher'])):\n",
    "                totalsuccess=totalsuccess+1\n",
    "    return float(totalsuccess)/float(totalbooks)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0302419354839\n",
      "CPU times: user 15.1 s, sys: 174 ms, total: 15.3 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "weightdict = {'Author':0.4,'Title':0.5,'Publisher':0.1}\n",
    "print predict_percentage(dftrain,dfval,4,weightdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 5min, sys: 30.3 s, total: 1h 5min 31s\n",
      "Wall time: 1h 12min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stepsize = 0.05\n",
    "\n",
    "Aws = np.arange(0,1,stepsize)\n",
    "\n",
    "accuracy_list = []\n",
    "for A in Aws:\n",
    "    Tws = np.arange(0,1-A,stepsize)\n",
    "    for T in Tws:\n",
    "        P = 1-A-T\n",
    "        weightdict = {'Author':A,'Publisher':P,'Title':T}\n",
    "        percentage = predict_percentage(dftrain,dfval,4,weightdict)\n",
    "        accuracy = weightdict\n",
    "        accuracy['accuracy'] = percentage\n",
    "        accuracy_list = accuracy_list+[accuracy]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('accuracy_hum.json', 'w') as fp:\n",
    "    json.dump(accuracy_list, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Title</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.017473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.016801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.016801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.016801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.015457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.015457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.015457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.015457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Author  Publisher  Title  accuracy\n",
       "114    0.30       0.25   0.45  0.030914\n",
       "168    0.55       0.30   0.15  0.030914\n",
       "151    0.45       0.20   0.35  0.030914\n",
       "123    0.35       0.45   0.20  0.030914\n",
       "62     0.15       0.60   0.25  0.030914\n",
       "122    0.35       0.50   0.15  0.030914\n",
       "121    0.35       0.55   0.10  0.030914\n",
       "59     0.15       0.75   0.10  0.030914\n",
       "58     0.15       0.80   0.05  0.030914\n",
       "115    0.30       0.20   0.50  0.030914\n",
       "156    0.50       0.45   0.05  0.030914\n",
       "157    0.50       0.40   0.10  0.030914\n",
       "158    0.50       0.35   0.15  0.030914\n",
       "159    0.50       0.30   0.20  0.030914\n",
       "160    0.50       0.25   0.25  0.030914\n",
       "161    0.50       0.20   0.30  0.030914\n",
       "162    0.50       0.15   0.35  0.030914\n",
       "163    0.50       0.10   0.40  0.030914\n",
       "120    0.35       0.60   0.05  0.030914\n",
       "106    0.30       0.65   0.05  0.030914\n",
       "93     0.25       0.60   0.15  0.030914\n",
       "150    0.45       0.25   0.30  0.030914\n",
       "149    0.45       0.30   0.25  0.030914\n",
       "148    0.45       0.35   0.20  0.030914\n",
       "137    0.40       0.35   0.25  0.030914\n",
       "91     0.25       0.70   0.05  0.030914\n",
       "94     0.25       0.55   0.20  0.030914\n",
       "131    0.35       0.05   0.60  0.030914\n",
       "133    0.40       0.55   0.05  0.030914\n",
       "134    0.40       0.50   0.10  0.030914\n",
       "..      ...        ...    ...       ...\n",
       "54     0.10       0.15   0.75  0.017473\n",
       "30     0.05       0.45   0.50  0.016801\n",
       "32     0.05       0.35   0.60  0.016801\n",
       "31     0.05       0.40   0.55  0.016801\n",
       "33     0.05       0.30   0.65  0.016129\n",
       "34     0.05       0.25   0.70  0.016129\n",
       "36     0.05       0.15   0.80  0.015457\n",
       "37     0.05       0.10   0.85  0.015457\n",
       "38     0.05       0.05   0.90  0.015457\n",
       "35     0.05       0.20   0.75  0.015457\n",
       "10     0.00       0.50   0.50  0.013441\n",
       "2      0.00       0.90   0.10  0.013441\n",
       "3      0.00       0.85   0.15  0.013441\n",
       "4      0.00       0.80   0.20  0.013441\n",
       "5      0.00       0.75   0.25  0.013441\n",
       "6      0.00       0.70   0.30  0.013441\n",
       "7      0.00       0.65   0.35  0.013441\n",
       "8      0.00       0.60   0.40  0.013441\n",
       "9      0.00       0.55   0.45  0.013441\n",
       "1      0.00       0.95   0.05  0.013441\n",
       "11     0.00       0.45   0.55  0.013441\n",
       "12     0.00       0.40   0.60  0.013441\n",
       "13     0.00       0.35   0.65  0.013441\n",
       "14     0.00       0.30   0.70  0.013441\n",
       "15     0.00       0.25   0.75  0.013441\n",
       "16     0.00       0.20   0.80  0.013441\n",
       "17     0.00       0.15   0.85  0.013441\n",
       "18     0.00       0.10   0.90  0.013441\n",
       "19     0.00       0.05   0.95  0.013441\n",
       "0      0.00       1.00   0.00  0.000672\n",
       "\n",
       "[210 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df = pd.DataFrame(accuracy_list)\n",
    "accuracy_df = accuracy_df.sort('accuracy',ascending=False)\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Publisher': 0.32882352941176479, 'Title': 0.19294117647058831, 'accuracy': 0.030913978494623649, 'Author': 0.47823529411764687}\n"
     ]
    }
   ],
   "source": [
    "bestweightdict = dict(accuracy_df[accuracy_df['accuracy']==accuracy_df['accuracy'].max()].mean())\n",
    "print bestweightdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge train and validation set\n",
    "dftrainandval = pd.concat([dftrain,dfval])\n",
    "dftrainandval = dftrainandval.reset_index()\n",
    "dftrainandval.drop('index', axis=1, inplace=True)\n",
    "\n",
    "#dataframe of all books in train and val data(no duplicates)\n",
    "dfbookall = dftrainandval[['Author','Title','Publisher','ISBN']]\n",
    "dfbookall = dfbookall[~dfbookall.duplicated()]\n",
    "dfbookall = dfbookall.reset_index()\n",
    "dfbookall.drop('index', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2725,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_entire_list_all = np.array([])\n",
    "for a in np.unique(dfbookall['Author']):\n",
    "    author_entire_list_all = np.append(author_entire_list_all,author_to_list(a))\n",
    "author_entire_list_all = np.unique(author_entire_list_all)\n",
    "author_entire_list_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make new simmat for merged dataframe\n",
    "#Make binary author lists: Nbooks X Nauthors matrix\n",
    "#Use author_entire_list for index-author matching\n",
    "Xauthor_all = np.zeros((dfbookall.index.shape[0],author_entire_list_all.shape[0]))\n",
    "for ind in range(dfbookall.shape[0]):\n",
    "    alist = author_to_list(dfbookall.iloc[ind]['Author'])\n",
    "    for a in alist:\n",
    "        aind = np.where(author_entire_list_all==a)[0][0]\n",
    "        Xauthor_all[ind,aind] = 1\n",
    "        \n",
    "#Make binary publisher lists: Nbooks X Npublihser matrix\n",
    "#use publisher_train or publisher_train_dict for index matching\n",
    "publisher_list_all = np.unique(dfbookall['Publisher'])\n",
    "Xpublisher_all = np.zeros((dfbookall.index.shape[0],publisher_list_all.shape[0]))\n",
    "for ind in range(dfbookall.shape[0]):\n",
    "    pub = dfbookall.iloc[ind]['Publisher']\n",
    "    pind = np.where(publisher_list_all==pub)[0][0]\n",
    "    Xpublisher_all[ind,pind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 19s, sys: 4.35 s, total: 4min 24s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Update similarity matrix for titles:\n",
    "Nbooks_all =dfbookall.index.shape[0]\n",
    "simmat_title_all = np.zeros((Nbooks_all,Nbooks_all))\n",
    "Nbooks = dfbook.index.shape[0]\n",
    "for i in range(Nbooks,Nbooks_all):\n",
    "    for j in range(Nbooks):\n",
    "        simmat_title_all[i,j] = similar(dfbookall.iloc[i]['Title'],dfbookall.iloc[j]['Title'])\n",
    "        simmat_title_all[j,i] = simmat_title_all[i,j]\n",
    "        \n",
    "for i in range(Nbooks,Nbooks_all):\n",
    "    simmat_title_all[i,i] = 1.0\n",
    "    for j in range(i+1,Nbooks_all):\n",
    "        simmat_title_all[i,j] = similar(dfbookall.iloc[i]['Title'],dfbookall.iloc[j]['Title'])\n",
    "        simmat_title_all[j,i] = simmat_title_all[i,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simmat_author_all = Xauthor_all.dot(Xauthor_all.T)\n",
    "simmat_publisher_all = Xpublisher_all.dot(Xpublisher_all.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0286738351254\n"
     ]
    }
   ],
   "source": [
    "#Estimate Test error\n",
    "testerror = predict_percentage(dftrainandval,dftest,3,bestweightdict,\n",
    "                               simmat_author=simmat_author_all,simmat_title=simmat_title_all,\n",
    "                               simmat_publisher=simmat_publisher_all,dfbook=dfbookall)\n",
    "print testerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02956989247311828"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_percentage(dftrain,dftest,3,bestweightdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
