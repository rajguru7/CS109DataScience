{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyyoo/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import scipy.sparse as sparse\n",
    "import sklearn.metrics as metrics\n",
    "import sys as sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "testdata = pd.read_csv(\"Test_Train_Sets/Reg_test.csv\")\n",
    "traindata = pd.read_csv(\"Test_Train_Sets/Reg_train.csv\")\n",
    "valdata = pd.read_csv(\"Test_Train_Sets/Reg_validate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10394, 18), (951, 18), (1268, 18))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.shape, testdata.shape, valdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class</th>\n",
       "      <th>Category</th>\n",
       "      <th>Author</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Pub_Date</th>\n",
       "      <th>Order_Time</th>\n",
       "      <th>Count</th>\n",
       "      <th>Cart</th>\n",
       "      <th>Cart_Date</th>\n",
       "      <th>Device</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>user_purchase_count</th>\n",
       "      <th>book_sell_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>파스칼의 팡세</td>\n",
       "      <td>299</td>\n",
       "      <td>20141218</td>\n",
       "      <td>주문</td>\n",
       "      <td>종교</td>\n",
       "      <td>&lt;블레즈 파스칼&gt; 저/&lt;조병준&gt; 역</td>\n",
       "      <td>9.788998e+12</td>\n",
       "      <td>샘솟는기쁨</td>\n",
       "      <td>20140526</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기기PID_PC</td>\n",
       "      <td>경상북도</td>\n",
       "      <td>안동시</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>내 안의 죄 죽이기</td>\n",
       "      <td>736</td>\n",
       "      <td>20140603</td>\n",
       "      <td>주문</td>\n",
       "      <td>종교</td>\n",
       "      <td>&lt;존 오웬&gt; 저/&lt;김창대&gt; 역</td>\n",
       "      <td>9.788993e+12</td>\n",
       "      <td>브니엘</td>\n",
       "      <td>20140211</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기기PID_PC</td>\n",
       "      <td>충청남도</td>\n",
       "      <td>당진시</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>전능자의 그늘</td>\n",
       "      <td>937</td>\n",
       "      <td>20140912</td>\n",
       "      <td>주문</td>\n",
       "      <td>종교</td>\n",
       "      <td>&lt;엘리자베스 엘리엇&gt; 저/&lt;윤종석&gt; 역</td>\n",
       "      <td>9.788990e+12</td>\n",
       "      <td>복있는사람</td>\n",
       "      <td>20080630</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기기PID_PC</td>\n",
       "      <td>경기도</td>\n",
       "      <td>포천시</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gods at war 거짓신들의 전쟁</td>\n",
       "      <td>937</td>\n",
       "      <td>20140912</td>\n",
       "      <td>주문</td>\n",
       "      <td>종교</td>\n",
       "      <td>&lt;카일 아이들먼&gt; 저/&lt;배응준&gt; 역</td>\n",
       "      <td>9.788961e+12</td>\n",
       "      <td>규장</td>\n",
       "      <td>20130227</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기기PID_PC</td>\n",
       "      <td>경기도</td>\n",
       "      <td>포천시</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>무정부주의와 기독교</td>\n",
       "      <td>1007</td>\n",
       "      <td>20140901</td>\n",
       "      <td>주문</td>\n",
       "      <td>종교</td>\n",
       "      <td>&lt;자끄 엘륄&gt; 저/&lt;이창헌&gt; 역</td>\n",
       "      <td>9.788971e+12</td>\n",
       "      <td>대장간</td>\n",
       "      <td>20111027</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기기PID_PC</td>\n",
       "      <td>경기도</td>\n",
       "      <td>의정부시</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Title    ID      Date Class Category                 Author          ISBN Publisher  Pub_Date  Order_Time  Count Cart  Cart_Date    Device Address1 Address2  user_purchase_count  book_sell_count\n",
       "0               파스칼의 팡세   299  20141218    주문       종교    <블레즈 파스칼> 저/<조병준> 역  9.788998e+12     샘솟는기쁨  20140526          19      1    N        NaN  기기PID_PC     경상북도      안동시                    1                3\n",
       "1            내 안의 죄 죽이기   736  20140603    주문       종교       <존 오웬> 저/<김창대> 역  9.788993e+12       브니엘  20140211          21      1    N        NaN  기기PID_PC     충청남도      당진시                    1                4\n",
       "2               전능자의 그늘   937  20140912    주문       종교  <엘리자베스 엘리엇> 저/<윤종석> 역  9.788990e+12     복있는사람  20080630          22      1    N        NaN  기기PID_PC      경기도      포천시                    2                4\n",
       "3  gods at war 거짓신들의 전쟁   937  20140912    주문       종교    <카일 아이들먼> 저/<배응준> 역  9.788961e+12        규장  20130227          22      1    N        NaN  기기PID_PC      경기도      포천시                    2                4\n",
       "4            무정부주의와 기독교  1007  20140901    주문       종교      <자끄 엘륄> 저/<이창헌> 역  9.788971e+12       대장간  20111027          17      1    N        NaN  기기PID_PC      경기도     의정부시                    2                1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4629 different books and 3815 different users in traindata\n",
      "757 different books and 317 different users in testdata\n",
      "971 different books and 317 different users in valdata\n"
     ]
    }
   ],
   "source": [
    "print '%d different books and %d different users in traindata' %(np.unique(traindata['Title']).shape[0],np.unique(traindata['ID']).shape[0])\n",
    "print '%d different books and %d different users in testdata' %(np.unique(testdata['Title']).shape[0],np.unique(testdata['ID']).shape[0])\n",
    "print '%d different books and %d different users in valdata' %(np.unique(valdata['Title']).shape[0],np.unique(valdata['ID']).shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataframe that contains only useful informations\n",
    "usefulcol = ['Title','ID','Class','Category','Author','ISBN','Count','Address1','Address2','Publisher']\n",
    "dftrain = traindata[usefulcol]\n",
    "dftest = testdata[usefulcol]\n",
    "dfval = valdata[usefulcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function that calculates similarity between two strings\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4629 3267 729\n"
     ]
    }
   ],
   "source": [
    "title_train = np.unique(dftrain['Title'].values)\n",
    "author_train = np.unique(dftrain['Author'].values)\n",
    "publisher_train = np.unique(dftrain['Publisher'].values)\n",
    "title_train_dict = {i:t for i,t in enumerate(title_train)}\n",
    "author_train_dict = {i:t for i,t in enumerate(author_train)}\n",
    "publisher_train_dict = {i:t for i,t in enumerate(publisher_train)}\n",
    "print title_train.shape[0],author_train.shape[0],publisher_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def author_to_list(author):\n",
    "    #split the list of authors in a single string into a numpy list of authors. remove brackets, '저', '역', '그림', '/', and etc\n",
    "    #remove translater\n",
    "    if author != author:\n",
    "        newauthorlist = []\n",
    "    else:\n",
    "        split_list = np.array(['/'])\n",
    "        mask = np.array([s in author for s in split_list])\n",
    "        split_list = split_list[mask]\n",
    "        \n",
    "        for s in split_list:\n",
    "            author = re.sub(s,' ..',author)\n",
    "        authorlist = author.split(' ..')\n",
    "        authorlist = np.array(filter(None,authorlist))\n",
    "        \n",
    "        translatormask = np.array([(' 역' in a) or (' 공역' in a) or \n",
    "                                   (' 편역' in a) or (' 감수' in a) or \n",
    "                                   (' 옮김' in a) or (' 등역' in a) or\n",
    "                                   (' 엮음' in a) for a in authorlist])\n",
    "        authorlist = authorlist[~translatormask]\n",
    "        \n",
    "        remove_str_list = np.array(['<','>',' 그림',' 저',' 공저',' 글', ' 등저',' 공편','편'])\n",
    "        newauthorlist = np.array([])\n",
    "        for astr in authorlist:\n",
    "            alist = np.array(astr.split(','))\n",
    "            for i,a in enumerate(alist):\n",
    "                for s in remove_str_list:\n",
    "                    a = re.sub(s,'',a)\n",
    "                alist.flat[i]=a\n",
    "            newauthorlist = np.append(newauthorlist,alist)\n",
    "                \n",
    "    return newauthorlist       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataframe of all books (no duplicates)\n",
    "dfbook = dftrain[['Author','Title','Publisher','ISBN']]\n",
    "dfbook = dfbook[~dfbook.duplicated()]\n",
    "dfbook = dfbook.reset_index()\n",
    "dfbook.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make list of all authors\n",
    "author_entire_list = np.array([])\n",
    "for a in author_train:\n",
    "    author_entire_list = np.append(author_entire_list,author_to_list(a))\n",
    "author_entire_list = np.unique(author_entire_list)\n",
    "author_entire_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make binary author lists: Nbooks X Nauthors matrix\n",
    "#Use author_entire_list for index-author matching\n",
    "Xauthor = np.zeros((dfbook.index.shape[0],author_entire_list.shape[0]))\n",
    "for ind in dfbook.index:\n",
    "    alist = author_to_list(dfbook.iloc[ind]['Author'])\n",
    "    for a in alist:\n",
    "        aind = np.where(author_entire_list==a)[0][0]\n",
    "        Xauthor[ind,aind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.savetxt('Xauthor_Rel.txt',Xauthor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make binary publisher lists: Nbooks X Npublihser matrix\n",
    "#use publisher_train or publisher_train_dict for index matching\n",
    "Xpublisher = np.zeros((dfbook.index.shape[0],publisher_train.shape[0]))\n",
    "for ind in dfbook.index:\n",
    "    pub = dfbook.iloc[ind]['Publisher']\n",
    "    pind = np.where(publisher_train==pub)[0][0]\n",
    "    Xpublisher[ind,pind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.savetxt('Xpublisher_Rel.txt',Xpublisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 51min 22s, sys: 2min 25s, total: 1h 53min 47s\n",
      "Wall time: 1h 59min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Make similarity matrix for titles: Nbooks X Nbooks matrix\n",
    "#Use dfbooks for index-title matching\n",
    "Nbooks =dfbook.index.shape[0]\n",
    "simmat_title = np.zeros((Nbooks,Nbooks))\n",
    "for i in range(Nbooks):\n",
    "    simmat_title[i,i] = 1.0\n",
    "    for j in range(i+1,Nbooks):\n",
    "        simmat_title[i,j] = similar(dfbook.iloc[i]['Title'],dfbook.iloc[j]['Title'])\n",
    "        simmat_title[j,i] = simmat_title[i,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.savetxt('simmat_title_Rel.txt',simmat_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#similarity matrices of author and publisher\n",
    "simmat_author = Xauthor.dot(Xauthor.T)\n",
    "simmat_publisher = Xpublisher.dot(Xpublisher.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_based_on_similarity(dftrain,userid,Nrec,simmat,dfbook=dfbook):\n",
    "    #recommend Nrec books similar to the books that the chosen user has bought so far\n",
    "    #input: \n",
    "    # dftrain: training data\n",
    "    # userid: id of the user\n",
    "    # Nrec: Number of books to be recommended\n",
    "    # dfbook: the dataframes of books\n",
    "    # simmat: Nbooks X Nbooks similarity matrix\n",
    "    usertrans = dftrain[dftrain['ID']==userid]  #user transaction\n",
    "    usertrans = usertrans[['Author','Title','Publisher','ISBN']]\n",
    "    usertrans = usertrans[~usertrans.duplicated()]\n",
    "    excludeind = np.array([])\n",
    "    simvec = np.zeros(simmat.shape[1])\n",
    "    for ind in usertrans.index:\n",
    "        bookind = dfbook[(dfbook['Title']==usertrans[usertrans.index == ind]['Title'].values[0]) \n",
    "                         & (dfbook['Publisher']==usertrans[usertrans.index == ind]['Publisher'].values[0])].index[0]\n",
    "        simvec = simvec+simmat[bookind,:]\n",
    "        excludeind = np.append(excludeind,[bookind])\n",
    "    simvec = simvec/usertrans.index.shape[0]\n",
    "    dfsimvec = dfbook\n",
    "    dfsimvec['Similarity'] = simvec\n",
    "\n",
    "    dfsimvec = dfsimvec.iloc[filter(lambda x: x not in excludeind,dfsimvec.index)]\n",
    "    return dfsimvec.sort('Similarity',ascending=False)[:Nrec]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function that estimates the prediction accuracy\n",
    "def predict_percentage(dftrain,dftest,Nrec,weightdict,simmat_author=simmat_author,\n",
    "                       simmat_title=simmat_title,simmat_publisher=simmat_publisher,dfbook=dfbook):\n",
    "    simmat = weightdict['Author']*simmat_author+weightdict['Title']*simmat_title\n",
    "    +weightdict['Publisher']*simmat_publisher\n",
    "    testusers = np.unique(dftest['ID'].values)\n",
    "    totalbooks = 0\n",
    "    totalsuccess = 0\n",
    "    for user in testusers:\n",
    "        dfrec = recommend_based_on_similarity(dftrain,user,Nrec,simmat,dfbook=dfbook)\n",
    "        dftestuser = dftest[dftest['ID']==user]\n",
    "        totalbooks = totalbooks+Nrec\n",
    "        for i in range(dfrec.shape[0]):\n",
    "            if np.any((dftestuser['Title']==dfrec.iloc[i]['Title']) \n",
    "                & (dftestuser['Publisher']==dfrec.iloc[i]['Publisher'])):\n",
    "                totalsuccess=totalsuccess+1\n",
    "    return float(totalsuccess)/float(totalbooks)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 33min 34s, sys: 3min 8s, total: 1h 36min 43s\n",
      "Wall time: 1h 47min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time{\n",
    "#Grid Search to find best combination of (w_A,w_P,w_T)\n",
    "stepsize = 0.05\n",
    "\n",
    "Aws = np.arange(0,1,stepsize)\n",
    "\n",
    "accuracy_list = []\n",
    "for A in Aws:\n",
    "    Tws = np.arange(0,1-A,stepsize)\n",
    "    for T in Tws:\n",
    "        P = 1-A-T\n",
    "        weightdict = {'Author':A,'Publisher':P,'Title':T}\n",
    "        percentage = predict_percentage(dftrain,dfval,4,weightdict)\n",
    "        accuracy = weightdict\n",
    "        accuracy['accuracy'] = percentage\n",
    "        accuracy_list = accuracy_list+[accuracy]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('accuracy_rel.json', 'w') as fp:\n",
    "    json.dump(accuracy_list, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_df = pd.DataFrame(accuracy_list)\n",
    "accuracy_df = accuracy_df.sort('accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Publisher': 0.33333333333333337, 'Title': 0.16111111111111109, 'accuracy': 0.048895899053627803, 'Author': 0.50555555555555554}\n"
     ]
    }
   ],
   "source": [
    "bestweightdict = dict(accuracy_df[accuracy_df['accuracy']==accuracy_df['accuracy'].max()].mean())\n",
    "print bestweightdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge train and validation set\n",
    "dftrainandval = pd.concat([dftrain,dfval])\n",
    "dftrainandval = dftrainandval.reset_index()\n",
    "dftrainandval.drop('index', axis=1, inplace=True)\n",
    "\n",
    "#dataframe of all books in train and val data(no duplicates)\n",
    "dfbookall = dftrainandval[['Author','Title','Publisher','ISBN']]\n",
    "dfbookall = dfbookall[~dfbookall.duplicated()]\n",
    "dfbookall = dfbookall.reset_index()\n",
    "dfbookall.drop('index', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_entire_list_all = np.array([])\n",
    "for a in np.unique(dfbookall['Author']):\n",
    "    author_entire_list_all = np.append(author_entire_list_all,author_to_list(a))\n",
    "author_entire_list_all = np.unique(author_entire_list_all)\n",
    "author_entire_list_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make new simmat for merged dataframe\n",
    "#Make binary author lists: Nbooks X Nauthors matrix\n",
    "#Use author_entire_list for index-author matching\n",
    "Xauthor_all = np.zeros((dfbookall.index.shape[0],author_entire_list_all.shape[0]))\n",
    "for ind in range(dfbookall.shape[0]):\n",
    "    alist = author_to_list(dfbookall.iloc[ind]['Author'])\n",
    "    for a in alist:\n",
    "        aind = np.where(author_entire_list_all==a)[0][0]\n",
    "        Xauthor_all[ind,aind] = 1\n",
    "        \n",
    "#Make binary publisher lists: Nbooks X Npublihser matrix\n",
    "#use publisher_train or publisher_train_dict for index matching\n",
    "publisher_list_all = np.unique(dfbookall['Publisher'])\n",
    "Xpublisher_all = np.zeros((dfbookall.index.shape[0],publisher_list_all.shape[0]))\n",
    "for ind in range(dfbookall.shape[0]):\n",
    "    pub = dfbookall.iloc[ind]['Publisher']\n",
    "    pind = np.where(publisher_list_all==pub)[0][0]\n",
    "    Xpublisher_all[ind,pind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 23s, sys: 10.6 s, total: 25min 34s\n",
      "Wall time: 31min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Update similarity matrix for titles:\n",
    "Nbooks_all =dfbookall.index.shape[0]\n",
    "simmat_title_all = np.zeros((Nbooks_all,Nbooks_all))\n",
    "Nbooks = dfbook.index.shape[0]\n",
    "for i in range(Nbooks,Nbooks_all):\n",
    "    for j in range(Nbooks):\n",
    "        simmat_title_all[i,j] = similar(dfbookall.iloc[i]['Title'],dfbookall.iloc[j]['Title'])\n",
    "        simmat_title_all[j,i] = simmat_title_all[i,j]\n",
    "        \n",
    "for i in range(Nbooks,Nbooks_all):\n",
    "    simmat_title_all[i,i] = 1.0\n",
    "    for j in range(i+1,Nbooks_all):\n",
    "        simmat_title_all[i,j] = similar(dfbookall.iloc[i]['Title'],dfbookall.iloc[j]['Title'])\n",
    "        simmat_title_all[j,i] = simmat_title_all[i,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simmat_author_all = Xauthor_all.dot(Xauthor_all.T)\n",
    "simmat_publisher_all = Xpublisher_all.dot(Xpublisher_all.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0399579390116\n"
     ]
    }
   ],
   "source": [
    "#Estimate Test error\n",
    "testerror = predict_percentage(dftrainandval,dftest,3,bestweightdict,\n",
    "                               simmat_author=simmat_author_all,simmat_title=simmat_title_all,\n",
    "                               simmat_publisher=simmat_publisher_all,dfbook=dfbookall)\n",
    "print testerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;자끄 엘륄&gt; 저/&lt;이창헌&gt; 역</td>\n",
       "      <td>무정부주의와 기독교</td>\n",
       "      <td>대장간</td>\n",
       "      <td>9.788971e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Author       Title Publisher          ISBN\n",
       "4  <자끄 엘륄> 저/<이창헌> 역  무정부주의와 기독교       대장간  9.788971e+12"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfbook[dfbook['Title']=='무정부주의와 기독교']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simmat = bestweightdict['Author']*simmat_author+bestweightdict['Publisher']*simmat_publisher+bestweightdict['Title']*simmat_title\n",
    "simvec = simmat[4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author       <자끄 엘륄> 저/<이창헌> 역\n",
      "Title               무정부주의와 기독교\n",
      "Publisher                  대장간\n",
      "ISBN              9.788971e+12\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print dfbook.iloc[4]\n",
    "dfsimvec = dfbook\n",
    "dfsimvec['similarity'] = simvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Recommend 30 books similar to the chosen book\n",
    "dfsimvec = dfsimvec.sort('similarity',ascending=False)\n",
    "dfsimvec = (dfsimvec[['ISBN','similarity','Title','Author','Publisher']])\n",
    "dfsimvec.iloc[0:30].to_csv('무정부주의와기독교_similarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
