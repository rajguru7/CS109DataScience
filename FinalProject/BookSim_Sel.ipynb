{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyyoo/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import scipy.sparse as sparse\n",
    "import sklearn.metrics as metrics\n",
    "import sys as sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata = pd.read_csv(\"Test_Train_Sets/Sel_test.csv\")\n",
    "traindata = pd.read_csv(\"Test_Train_Sets/Sel_train.csv\")\n",
    "valdata = pd.read_csv(\"Test_Train_Sets/Sel_validate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15808, 18), (1194, 18), (1592, 18))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.shape, testdata.shape, valdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2528 different books and 7204 different users in traindata\n",
      "559 different books and 398 different users in testdata\n",
      "679 different books and 398 different users in valdata\n"
     ]
    }
   ],
   "source": [
    "print '%d different books and %d different users in traindata' %(np.unique(traindata['Title']).shape[0],np.unique(traindata['ID']).shape[0])\n",
    "print '%d different books and %d different users in testdata' %(np.unique(testdata['Title']).shape[0],np.unique(testdata['ID']).shape[0])\n",
    "print '%d different books and %d different users in valdata' %(np.unique(valdata['Title']).shape[0],np.unique(valdata['ID']).shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataframe that contains only useful informations\n",
    "usefulcol = ['Title','ID','Class','Category','Author','ISBN','Count','Address1','Address2','Publisher']\n",
    "dftrain = traindata[usefulcol]\n",
    "dftest = testdata[usefulcol]\n",
    "dfval = valdata[usefulcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2528 2128 681\n"
     ]
    }
   ],
   "source": [
    "title_train = np.unique(dftrain['Title'].values)\n",
    "author_train = np.unique(dftrain['Author'].values)\n",
    "publisher_train = np.unique(dftrain['Publisher'].values)\n",
    "title_train_dict = {i:t for i,t in enumerate(title_train)}\n",
    "author_train_dict = {i:t for i,t in enumerate(author_train)}\n",
    "publisher_train_dict = {i:t for i,t in enumerate(publisher_train)}\n",
    "print title_train.shape[0],author_train.shape[0],publisher_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def author_to_list(author):\n",
    "    #split the list of authors in a single string into a numpy list of authors. remove brackets, '저', '역', '그림', '/', and etc\n",
    "    #remove translater\n",
    "    if author != author:\n",
    "        newauthorlist = []\n",
    "    else:\n",
    "        split_list = np.array(['/'])\n",
    "        mask = np.array([s in author for s in split_list])\n",
    "        split_list = split_list[mask]\n",
    "        \n",
    "        for s in split_list:\n",
    "            author = re.sub(s,' ..',author)\n",
    "        authorlist = author.split(' ..')\n",
    "        authorlist = np.array(filter(None,authorlist))\n",
    "        \n",
    "        translatormask = np.array([(' 역' in a) or (' 공역' in a) or \n",
    "                                   (' 편역' in a) or (' 감수' in a) or \n",
    "                                   (' 옮김' in a) or (' 등역' in a) or\n",
    "                                   (' 엮음' in a) for a in authorlist])\n",
    "        authorlist = authorlist[~translatormask]\n",
    "        \n",
    "        remove_str_list = np.array(['<','>',' 그림',' 저',' 공저',' 글', ' 등저',' 공편','편'])\n",
    "        newauthorlist = np.array([])\n",
    "        for astr in authorlist:\n",
    "            alist = np.array(astr.split(','))\n",
    "            for i,a in enumerate(alist):\n",
    "                for s in remove_str_list:\n",
    "                    a = re.sub(s,'',a)\n",
    "                alist.flat[i]=a\n",
    "            newauthorlist = np.append(newauthorlist,alist)\n",
    "                \n",
    "    return newauthorlist       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataframe of all books (no duplicates)\n",
    "dfbook = dftrain[['Author','Title','Publisher','ISBN']]\n",
    "dfbook = dfbook[~dfbook.duplicated()]\n",
    "dfbook = dfbook.reset_index()\n",
    "dfbook.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2253,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_entire_list = np.array([])\n",
    "for a in author_train:\n",
    "    author_entire_list = np.append(author_entire_list,author_to_list(a))\n",
    "author_entire_list = np.unique(author_entire_list)\n",
    "author_entire_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_entire_list_dict = {i:a for i,a in enumerate(author_entire_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make binary author lists: Nbooks X Nauthors matrix\n",
    "#Use author_entire_list for index-author matching\n",
    "Xauthor = np.zeros((dfbook.index.shape[0],author_entire_list.shape[0]))\n",
    "for ind in dfbook.index:\n",
    "    alist = author_to_list(dfbook.iloc[ind]['Author'])\n",
    "    for a in alist:\n",
    "        aind = np.where(author_entire_list==a)[0][0]\n",
    "        Xauthor[ind,aind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('Xauthor_Sel.txt',Xauthor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make binary publisher lists: Nbooks X Npublihser matrix\n",
    "#use publisher_train or publisher_train_dict for index matching\n",
    "Xpublisher = np.zeros((dfbook.index.shape[0],publisher_train.shape[0]))\n",
    "for ind in dfbook.index:\n",
    "    pub = dfbook.iloc[ind]['Publisher']\n",
    "    pind = np.where(publisher_train==pub)[0][0]\n",
    "    Xpublisher[ind,pind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('Xpublisher_Sel.txt',Xpublisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 25s, sys: 27.9 s, total: 26min 53s\n",
      "Wall time: 26min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Make similarity matrix for titles: Nbooks X Nbooks matrix\n",
    "#Use dfbooks for index-title matching\n",
    "Nbooks =dfbook.index.shape[0]\n",
    "simmat_title = np.zeros((Nbooks,Nbooks))\n",
    "for i in range(Nbooks):\n",
    "    simmat_title[i,i] = 1.0\n",
    "    for j in range(i+1,Nbooks):\n",
    "        simmat_title[i,j] = similar(dfbook.iloc[i]['Title'],dfbook.iloc[j]['Title'])\n",
    "        simmat_title[j,i] = simmat_title[i,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('simmat_title_Sel.txt',simmat_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simmat_author = Xauthor.dot(Xauthor.T)\n",
    "simmat_publisher = Xpublisher.dot(Xpublisher.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simmat = 0.5*simmat_title+0.4*simmat_author+0.1*simmat_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_based_on_similarity(dftrain,userid,Nrec,simmat,dfbook=dfbook):\n",
    "    #recommend Nrec books similar to the books that the chosen user has bought so far\n",
    "    #input: \n",
    "    # dftrain: training data\n",
    "    # userid: id of the user\n",
    "    # Nrec: Number of books to be recommended\n",
    "    # dfbook: the dataframes of books\n",
    "    # simmat: Nbooks X Nbooks similarity matrix\n",
    "    usertrans = dftrain[dftrain['ID']==userid]  #user transaction\n",
    "    usertrans = usertrans[['Author','Title','Publisher','ISBN']]\n",
    "    usertrans = usertrans[~usertrans.duplicated()]\n",
    "    excludeind = np.array([])\n",
    "    simvec = np.zeros(simmat.shape[1])\n",
    "    for ind in usertrans.index:\n",
    "        bookind = dfbook[(dfbook['Title']==usertrans[usertrans.index == ind]['Title'].values[0]) \n",
    "                         & (dfbook['Publisher']==usertrans[usertrans.index == ind]['Publisher'].values[0])].index[0]\n",
    "        simvec = simvec+simmat[bookind,:]\n",
    "        excludeind = np.append(excludeind,[bookind])\n",
    "    simvec = simvec/usertrans.index.shape[0]\n",
    "    dfsimvec = dfbook\n",
    "    dfsimvec['Similarity'] = simvec\n",
    "\n",
    "    dfsimvec = dfsimvec.iloc[filter(lambda x: x not in excludeind,dfsimvec.index)]\n",
    "    return dfsimvec.sort('Similarity',ascending=False)[:Nrec]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>&lt;이지성&gt; 저</td>\n",
       "      <td>[염가한정판매] 리딩으로 리드하라</td>\n",
       "      <td>문학동네</td>\n",
       "      <td>9.788955e+12</td>\n",
       "      <td>0.242798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>&lt;샘 혼&gt; 저/&lt;이상원&gt; 역</td>\n",
       "      <td>함부로 말하는 사람과 대화하는 법</td>\n",
       "      <td>갈매나무</td>\n",
       "      <td>9.788994e+12</td>\n",
       "      <td>0.238239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;샘 혼&gt; 저/&lt;이상원&gt; 역</td>\n",
       "      <td>적을 만들지 않는 대화법</td>\n",
       "      <td>갈매나무</td>\n",
       "      <td>9.788996e+12</td>\n",
       "      <td>0.237193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Author               Title Publisher          ISBN  Similarity\n",
       "1400          <이지성> 저  [염가한정판매] 리딩으로 리드하라      문학동네  9.788955e+12    0.242798\n",
       "1818  <샘 혼> 저/<이상원> 역  함부로 말하는 사람과 대화하는 법      갈매나무  9.788994e+12    0.238239\n",
       "19    <샘 혼> 저/<이상원> 역       적을 만들지 않는 대화법      갈매나무  9.788996e+12    0.237193"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_based_on_similarity(dftrain,dftest['ID'].values[10],3,simmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_percentage(dftrain,dftest,Nrec,weightdict,simmat_author=simmat_author,\n",
    "                       simmat_title=simmat_title,simmat_publisher=simmat_publisher,dfbook=dfbook):\n",
    "    simmat = weightdict['Author']*simmat_author+weightdict['Title']*simmat_title\n",
    "    +weightdict['Publisher']*simmat_publisher\n",
    "    testusers = np.unique(dftest['ID'].values)\n",
    "    totalbooks = 0\n",
    "    totalsuccess = 0\n",
    "    for user in testusers:\n",
    "        dfrec = recommend_based_on_similarity(dftrain,user,Nrec,simmat,dfbook=dfbook)\n",
    "        dftestuser = dftest[dftest['ID']==user]\n",
    "        totalbooks = totalbooks+Nrec\n",
    "        for i in range(dfrec.shape[0]):\n",
    "            if np.any((dftestuser['Title']==dfrec.iloc[i]['Title']) \n",
    "                & (dftestuser['Publisher']==dfrec.iloc[i]['Publisher'])):\n",
    "                totalsuccess=totalsuccess+1\n",
    "    return float(totalsuccess)/float(totalbooks)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0270100502513\n",
      "CPU times: user 16.1 s, sys: 129 ms, total: 16.2 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "weightdict = {'Author':0.4,'Title':0.5,'Publisher':0.1}\n",
    "print predict_percentage(dftrain,dfval,4,weightdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 7min, sys: 27.6 s, total: 1h 7min 28s\n",
      "Wall time: 1h 14min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stepsize = 0.05\n",
    "\n",
    "Aws = np.arange(0,1,stepsize)\n",
    "\n",
    "accuracy_list = []\n",
    "for A in Aws:\n",
    "    Tws = np.arange(0,1-A,stepsize)\n",
    "    for T in Tws:\n",
    "        P = 1-A-T\n",
    "        weightdict = {'Author':A,'Publisher':P,'Title':T}\n",
    "        percentage = predict_percentage(dftrain,dfval,4,weightdict)\n",
    "        accuracy = weightdict\n",
    "        accuracy['accuracy'] = percentage\n",
    "        accuracy_list = accuracy_list+[accuracy]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('accuracy_sel.json', 'w') as fp:\n",
    "    json.dump(accuracy_list, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Title</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.011307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.011307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.011307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.011307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.011307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.011307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.011307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.010678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.010050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.010050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Author  Publisher  Title  accuracy\n",
       "122    0.35       0.50   0.15  0.028266\n",
       "179    0.60       0.15   0.25  0.028266\n",
       "177    0.60       0.25   0.15  0.028266\n",
       "176    0.60       0.30   0.10  0.028266\n",
       "175    0.60       0.35   0.05  0.028266\n",
       "108    0.30       0.55   0.15  0.028266\n",
       "40     0.10       0.85   0.05  0.028266\n",
       "107    0.30       0.60   0.10  0.028266\n",
       "106    0.30       0.65   0.05  0.028266\n",
       "170    0.55       0.20   0.25  0.028266\n",
       "169    0.55       0.25   0.20  0.028266\n",
       "168    0.55       0.30   0.15  0.028266\n",
       "167    0.55       0.35   0.10  0.028266\n",
       "166    0.55       0.40   0.05  0.028266\n",
       "133    0.40       0.55   0.05  0.028266\n",
       "134    0.40       0.50   0.10  0.028266\n",
       "160    0.50       0.25   0.25  0.028266\n",
       "159    0.50       0.30   0.20  0.028266\n",
       "158    0.50       0.35   0.15  0.028266\n",
       "157    0.50       0.40   0.10  0.028266\n",
       "58     0.15       0.80   0.05  0.028266\n",
       "92     0.25       0.65   0.10  0.028266\n",
       "91     0.25       0.70   0.05  0.028266\n",
       "135    0.40       0.45   0.15  0.028266\n",
       "156    0.50       0.45   0.05  0.028266\n",
       "136    0.40       0.40   0.20  0.028266\n",
       "148    0.45       0.35   0.20  0.028266\n",
       "147    0.45       0.40   0.15  0.028266\n",
       "146    0.45       0.45   0.10  0.028266\n",
       "145    0.45       0.50   0.05  0.028266\n",
       "..      ...        ...    ...       ...\n",
       "54     0.10       0.15   0.75  0.011307\n",
       "32     0.05       0.35   0.60  0.011307\n",
       "34     0.05       0.25   0.70  0.011307\n",
       "35     0.05       0.20   0.75  0.011307\n",
       "56     0.10       0.05   0.85  0.011307\n",
       "55     0.10       0.10   0.80  0.011307\n",
       "33     0.05       0.30   0.65  0.011307\n",
       "36     0.05       0.15   0.80  0.010678\n",
       "37     0.05       0.10   0.85  0.010050\n",
       "38     0.05       0.05   0.90  0.010050\n",
       "6      0.00       0.70   0.30  0.009422\n",
       "8      0.00       0.60   0.40  0.009422\n",
       "7      0.00       0.65   0.35  0.009422\n",
       "2      0.00       0.90   0.10  0.009422\n",
       "5      0.00       0.75   0.25  0.009422\n",
       "4      0.00       0.80   0.20  0.009422\n",
       "3      0.00       0.85   0.15  0.009422\n",
       "10     0.00       0.50   0.50  0.009422\n",
       "9      0.00       0.55   0.45  0.009422\n",
       "15     0.00       0.25   0.75  0.009422\n",
       "11     0.00       0.45   0.55  0.009422\n",
       "12     0.00       0.40   0.60  0.009422\n",
       "13     0.00       0.35   0.65  0.009422\n",
       "14     0.00       0.30   0.70  0.009422\n",
       "16     0.00       0.20   0.80  0.009422\n",
       "17     0.00       0.15   0.85  0.009422\n",
       "18     0.00       0.10   0.90  0.009422\n",
       "19     0.00       0.05   0.95  0.009422\n",
       "1      0.00       0.95   0.05  0.009422\n",
       "0      0.00       1.00   0.00  0.000000\n",
       "\n",
       "[210 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df = pd.DataFrame(accuracy_list)\n",
    "accuracy_df = accuracy_df.sort('accuracy',ascending=False)\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Publisher': 0.33157894736842108, 'Title': 0.12894736842105259, 'accuracy': 0.028266331658291455, 'Author': 0.53947368421052611}\n"
     ]
    }
   ],
   "source": [
    "bestweightdict = dict(accuracy_df[accuracy_df['accuracy']==accuracy_df['accuracy'].max()].mean())\n",
    "print bestweightdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge train and validation set\n",
    "dftrainandval = pd.concat([dftrain,dfval])\n",
    "dftrainandval = dftrainandval.reset_index()\n",
    "dftrainandval.drop('index', axis=1, inplace=True)\n",
    "\n",
    "#dataframe of all books in train and val data(no duplicates)\n",
    "dfbookall = dftrainandval[['Author','Title','Publisher','ISBN']]\n",
    "dfbookall = dfbookall[~dfbookall.duplicated()]\n",
    "dfbookall = dfbookall.reset_index()\n",
    "dfbookall.drop('index', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2351,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_entire_list_all = np.array([])\n",
    "for a in np.unique(dfbookall['Author']):\n",
    "    author_entire_list_all = np.append(author_entire_list_all,author_to_list(a))\n",
    "author_entire_list_all = np.unique(author_entire_list_all)\n",
    "author_entire_list_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make new simmat for merged dataframe\n",
    "#Make binary author lists: Nbooks X Nauthors matrix\n",
    "#Use author_entire_list for index-author matching\n",
    "Xauthor_all = np.zeros((dfbookall.index.shape[0],author_entire_list_all.shape[0]))\n",
    "for ind in range(dfbookall.shape[0]):\n",
    "    alist = author_to_list(dfbookall.iloc[ind]['Author'])\n",
    "    for a in alist:\n",
    "        aind = np.where(author_entire_list_all==a)[0][0]\n",
    "        Xauthor_all[ind,aind] = 1\n",
    "        \n",
    "#Make binary publisher lists: Nbooks X Npublihser matrix\n",
    "#use publisher_train or publisher_train_dict for index matching\n",
    "publisher_list_all = np.unique(dfbookall['Publisher'])\n",
    "Xpublisher_all = np.zeros((dfbookall.index.shape[0],publisher_list_all.shape[0]))\n",
    "for ind in range(dfbookall.shape[0]):\n",
    "    pub = dfbookall.iloc[ind]['Publisher']\n",
    "    pind = np.where(publisher_list_all==pub)[0][0]\n",
    "    Xpublisher_all[ind,pind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 2.45 s, total: 2min 48s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Update similarity matrix for titles:\n",
    "Nbooks_all =dfbookall.index.shape[0]\n",
    "simmat_title_all = np.zeros((Nbooks_all,Nbooks_all))\n",
    "Nbooks = dfbook.index.shape[0]\n",
    "for i in range(Nbooks,Nbooks_all):\n",
    "    for j in range(Nbooks):\n",
    "        simmat_title_all[i,j] = similar(dfbookall.iloc[i]['Title'],dfbookall.iloc[j]['Title'])\n",
    "        simmat_title_all[j,i] = simmat_title_all[i,j]\n",
    "        \n",
    "for i in range(Nbooks,Nbooks_all):\n",
    "    simmat_title_all[i,i] = 1.0\n",
    "    for j in range(i+1,Nbooks_all):\n",
    "        simmat_title_all[i,j] = similar(dfbookall.iloc[i]['Title'],dfbookall.iloc[j]['Title'])\n",
    "        simmat_title_all[j,i] = simmat_title_all[i,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simmat_author_all = Xauthor_all.dot(Xauthor_all.T)\n",
    "simmat_publisher_all = Xpublisher_all.dot(Xpublisher_all.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0242881072027\n"
     ]
    }
   ],
   "source": [
    "#Estimate Test error\n",
    "testerror = predict_percentage(dftrainandval,dftest,3,bestweightdict,\n",
    "                               simmat_author=simmat_author_all,simmat_title=simmat_title_all,\n",
    "                               simmat_publisher=simmat_publisher_all,dfbook=dfbookall)\n",
    "print testerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023450586264656615"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_percentage(dftrain,dftest,3,bestweightdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
